<!-- Performance_Engineering/documentation.md -->
# Remark

The Performance Engineering component is under development currently. Summaries of each stage as well as detailed results are to be produces as planned step by step. As a result, the structuring of this component will be adjusted accordingly. 

# Performance Engineering & Optimisation

Several initial optimisations (multithreaded dataloading, M1â€‘specific GPU utilisation, etc.) have already been implementedâ€¯â€”â€¯see the Performance Engineering notes in the mainâ€¯README.md. A deeper, endâ€‘toâ€‘end analysis will follow once the May roadmap items (distillation, quantisation, latency tuning, etc.) have landed.

[![Status](https://img.shields.io/badge/status-planned-yellow)](../../)  
_Last updated: **MayÂ 2025** â€¢ Target release: **v0.2**_

> **Mission:** Continuously shrink latency, memory, and disk footprint of the cybersecurityâ€‘summariser stack while safeguarding ROUGE performance.

---

## Scope

| Area                                 | Why it matters                                   |
|--------------------------------------|--------------------------------------------------|
| **Model efficiency**                 | Faster inference & smaller deployable artefacts. |
| **Dataâ€‘pipeline throughput**         | Cuts total training time, speeds experiments.    |
| **Resource utilisation (CPUÂ /Â GPU)** | Enables lowâ€‘cost deployment & laptopâ€‘level dev.  |

---

## ğŸ—“ï¸Â Roadmap

<details>
<summary><strong>Checklist</strong> (expand)</summary>

- [ ] Distill scratch GPTâ€‘2 â†’ 14â€¯Mâ€‘param student  
- [ ] Convert distilled model to **INT8 ONNX** & benchmark  
- [ ] Latency profiling notebook (`perf_latency.ipynb`)  
- [ ] Pipeline refactor: parallelised JSONL preprocessing  
- [ ] Memory audit & gradientâ€‘checkpointing explainer  
- [ ] README update with before/after metrics table  

</details>

### Milestone table

| Week (JulyÂ 2025) | Deliverable | Owner | Notes |
|-----------------|-------------|-------|-------|
| JulyÂ 6Â â€“Â 10      | Distillation script (`distill.py`) | @you | teacherâ€¯=Â full GPTâ€‘2â€‘scratch |
| JulyÂ 11Â â€“Â 17     | ONNX INT8 quant + latency report   | @you | depends on distill.py |
| JulyÂ 18Â â€“Â 24     | Dataâ€‘prep refactor & benchmarks    | @you | pandas â†’ multiprocessing |
| JulyÂ 25Â â€“Â 31     | Memory optimisation & final doc PR | @you | includes profiling figures |

> **Tooling**: We will rely on *PyTorchÂ 2.3*, *onnxruntimeâ€‘gpu*, and *PyTorchÂ Profiler*.

---
## Machine Used For Benchmarking and Performance Engineering

**Operating System**
- Ubuntu 22.04.5 LTS (Jammy Jellyfish)

**CPU**
- Model: 11th Gen Intel(R) Core(TM) i7-11800H @ 2.30GHz
- Architecture: x64, 8 physical cores, 16 threads
- Max Frequency: 4.6 GHz

**Memory**
- Total System RAM: 32GB

**GPU**
- Model: NVIDIA GeForce RTX 3060 Laptop GPU
- CUDA Version: 12.8
- VRAM: 6 GB
- Driver: 570.133.07

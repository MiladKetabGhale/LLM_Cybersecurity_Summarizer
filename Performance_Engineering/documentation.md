<!-- Performance_Engineering/documentation.md -->
# Remark

The Performance Engineering component is under development currently. Summaries of each stage as well as detailed results are to be produces as planned step by step. As a result, the structuring of this component will be adjusted accordingly. 

# Performance Engineering & Optimisation

Several initial optimisations (multithreaded dataloading, M1â€‘specific GPU utilisation, etc.) have already been implementedâ€¯â€”â€¯see the Performance Engineering notes in the mainâ€¯README.md. A deeper, endâ€‘toâ€‘end analysis will follow once the May roadmap items (distillation, quantisation, latency tuning, etc.) have landed.

[![Status](https://img.shields.io/badge/status-planned-yellow)](../../)  
_Last updated: **MayÂ 2025** â€¢ Target release: **v0.2**_

> **Mission:** Continuously shrink latency, memory, and disk footprint of the cybersecurityâ€‘summariser stack while safeguarding ROUGE performance.

---

## Scope

| Area                                 | Why it matters                                   |
|--------------------------------------|--------------------------------------------------|
| **Model efficiency**                 | Faster inference & smaller deployable artefacts. |
| **Dataâ€‘pipeline throughput**         | Cuts total training time, speeds experiments.    |
| **Resource utilisation (CPUÂ /Â GPU)** | Enables lowâ€‘cost deployment & laptopâ€‘level dev.  |

---

## ğŸ—“ï¸Â MayÂ 2025 Roadmap

<details>
<summary><strong>Checklist</strong> (expand)</summary>

- [ ] Distill scratch GPTâ€‘2 â†’ 14â€¯Mâ€‘param student  
- [ ] Convert distilled model to **INT8 ONNX** & benchmark  
- [ ] Latency profiling notebook (`perf_latency.ipynb`)  
- [ ] Pipeline refactor: parallelised JSONL preprocessing  
- [ ] Memory audit & gradientâ€‘checkpointing explainer  
- [ ] README update with before/after metrics table  

</details>

### Milestone table

| Week (MayÂ 2025) | Deliverable | Owner | Notes |
|-----------------|-------------|-------|-------|
| MayÂ 6Â â€“Â 10      | Distillation script (`distill.py`) | @you | teacherâ€¯=Â full GPTâ€‘2â€‘scratch |
| MayÂ 11Â â€“Â 17     | ONNX INT8 quant + latency report   | @you | depends on distill.py |
| MayÂ 18Â â€“Â 24     | Dataâ€‘prep refactor & benchmarks    | @you | pandas â†’ multiprocessing |
| MayÂ 25Â â€“Â 31     | Memory optimisation & final doc PR | @you | includes profiling figures |

> **Tooling**: We will rely on *PyTorchÂ 2.3*, *onnxruntimeâ€‘gpu*, and *PyTorchÂ Profiler*.

---

## Future sections (will appear as PRs land)

```text
Performance_Engineering/
â”œâ”€â”€ distill.py                  # knowledgeâ€‘distillation driver
â”œâ”€â”€ quantize_onnx.py            # export + INT8 calibration
â”œâ”€â”€ perf_latency.ipynb          # latency profiling notebook
â””â”€â”€ README_perf_results.md      # sideâ€‘byâ€‘side before/after metrics
